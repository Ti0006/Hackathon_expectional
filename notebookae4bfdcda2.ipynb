{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8029c6a3",
   "metadata": {
    "papermill": {
     "duration": 0.007867,
     "end_time": "2023-06-24T17:01:53.131610",
     "exception": false,
     "start_time": "2023-06-24T17:01:53.123743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Language Identification in South African Text: Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95df412",
   "metadata": {
    "papermill": {
     "duration": 0.006456,
     "end_time": "2023-06-24T17:01:53.145284",
     "exception": false,
     "start_time": "2023-06-24T17:01:53.138828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook presents my approach to tackle the Language Identification Challenge on Kaggle. The challenge focuses on classifying text written in South Africa's 11 Official languages. The notebook covers data exploration, preprocessing, feature extraction, model training, evaluation, and submission generation. By leveraging machine learning techniques, I aim to develop a classification model that accurately predicts the language of a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39a2dd",
   "metadata": {
    "papermill": {
     "duration": 0.006417,
     "end_time": "2023-06-24T17:01:53.158586",
     "exception": false,
     "start_time": "2023-06-24T17:01:53.152169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21fb054c",
   "metadata": {
    "papermill": {
     "duration": 1.8065,
     "end_time": "2023-06-24T17:01:54.971826",
     "exception": false,
     "start_time": "2023-06-24T17:01:53.165326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88339c",
   "metadata": {
    "papermill": {
     "duration": 0.006598,
     "end_time": "2023-06-24T17:01:54.985590",
     "exception": false,
     "start_time": "2023-06-24T17:01:54.978992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e91c8663",
   "metadata": {
    "papermill": {
     "duration": 1.297391,
     "end_time": "2023-06-24T17:01:56.291622",
     "exception": true,
     "start_time": "2023-06-24T17:01:54.994231",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train_set.csv')\n",
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59f3ed99-1a03-4292-8605-6a822a4b490a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the full path or adjust the path accordingly\n",
    "train_file_path = 'train_set.csv'\n",
    "test_file_path = 'test_set.csv'\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(train_file_path)\n",
    "    test_df = pd.read_csv(test_file_path)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found. Please check the file paths: {train_file_path} and {test_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b207f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3a6f70b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "  lang_id                                               text\n",
      "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
      "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
      "2     eng  the province of kwazulu-natal department of tr...\n",
      "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
      "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
      "\n",
      "Test Dataset:\n",
      "   index                                               text\n",
      "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
      "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
      "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
      "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
      "4      5                      Winste op buitelandse valuta.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2ffc6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "208826b9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_df):\n",
    "    # Initializing the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fitting the vectorizer on the training data\n",
    "    vectorizer.fit(train_df['text'])\n",
    "\n",
    "    # Transforming the training and test data using the fitted vectorizer\n",
    "    train_features = vectorizer.transform(train_df['text'])\n",
    "    test_features = vectorizer.transform(test_df['text'])\n",
    "\n",
    "    return train_features, test_features, vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3b523",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da280e9e-9633-462b-a2d9-0cf184a9a280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_data(train_df, test_df):\n",
    "    # Assuming your DataFrame has a 'text' column containing the text data\n",
    "    train_text = train_df['text'].astype(str)\n",
    "    test_text = test_df['text'].astype(str)\n",
    "\n",
    "    # Use CountVectorizer for text representation\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_features = vectorizer.fit_transform(train_text)\n",
    "    test_features = vectorizer.transform(test_text)\n",
    "\n",
    "    return train_features, test_features, vectorizer\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'train_set.csv' and 'test_set.csv' with your actual file names or paths\n",
    "train_df = pd.read_csv('train_set.csv')\n",
    "test_df = pd.read_csv('test_set.csv')\n",
    "\n",
    "train_features, test_features, vectorizer = preprocess_data(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23ad24",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d5024423",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.9939385509753286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\J.Adeoye\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df['lang_id'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "lr_preds = lr_model.predict(X_val)\n",
    "\n",
    "# Calculate the F1 score\n",
    "lr_f1 = f1_score(y_val, lr_preds, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705d4dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d132e0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1 Score: 0.9175947192684192\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df['lang_id'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a k-Nearest Neighbors model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "knn_preds = knn_model.predict(X_val)\n",
    "\n",
    "# Calculate the F1 score\n",
    "knn_f1 = f1_score(y_val, knn_preds, average='weighted')\n",
    "\n",
    "print(\"KNN F1 Score:\", knn_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23da6079",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e1b3f39",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1 Score: 0.9915204291200247\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df['lang_id'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a Support Vector Machine (SVM) model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "svm_predictions = svm_model.predict(X_val)\n",
    "\n",
    "# Calculate the F1 score\n",
    "svm_f1 = f1_score(y_val, svm_predictions, average='weighted')\n",
    "\n",
    "print(\"SVM F1 Score:\", svm_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd0a221",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27658c72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score: 0.9989392771541917\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predictions = nb.predict(X_val)\n",
    "nb_f1 = f1_score(y_val, nb_predictions, average='weighted')\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ef28043-42bd-4274-80b7-1dc7bfa4d7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score on Validation Set: 0.9989392771541917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the data for model training\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df['lang_id'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Generating predictions on the validation set\n",
    "nb_predictions_val = nb_model.predict(X_val)\n",
    "nb_f1_val = f1_score(y_val, nb_predictions_val, average='weighted')\n",
    "print(\"Naive Bayes F1 Score on Validation Set:\", nb_f1_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bb64d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Generate predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ff51a0a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating predictions on the test set using the Naive Bayes model\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "test_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_df['index'], 'lang_id': test_predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d946a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Creating a csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aab624a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the submission CSV\n",
    "submission_df.to_csv('FinalSub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ab4fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b076c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7817e4-879f-40b0-a5a5-e23aa2fef8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.599363,
   "end_time": "2023-06-24T17:01:57.729565",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-24T17:01:39.130202",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
